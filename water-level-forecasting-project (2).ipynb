{"cells":[{"metadata":{"id":"8GuuGzrkJRoa"},"cell_type":"markdown","source":"# SET UP"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","id":"d7YytX2BJRog","outputId":"8594c98e-b42d-4b1a-96f8-ba8cbd5765b9","trusted":true},"cell_type":"code","source":"import os\nimport warnings\n\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 20, 8\n\nimport math\nfrom statsmodels.tsa.stattools import acf,pacf\nfrom statsmodels.tsa.stattools import adfuller\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\nimport math\n\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport plotly as py\nimport plotly.io as pio\nimport plotly.graph_objs as go\nfrom plotly.subplots import make_subplots\n\n\nfrom models import * \nfrom utils import * \n\n# Show charts when running kernel\ninit_notebook_mode(connected=True)\n\n# Change default background color for all visualizations\nlayout=go.Layout(paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(250,250,250,0.8)')\nfig = go.Figure(layout=layout)\ntemplated_fig = pio.to_templated(fig)\npio.templates['my_template'] = templated_fig.layout.template\npio.templates.default = 'my_template'\n\n","execution_count":3,"outputs":[{"output_type":"stream","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n","name":"stderr"},{"output_type":"display_data","data":{"text/html":"        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        "},"metadata":{}},{"output_type":"display_data","data":{"text/html":"        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        "},"metadata":{}}]},{"metadata":{"id":"3KDL4alMJRoq"},"cell_type":"markdown","source":"# Feature Engineering"},{"metadata":{"id":"2wWdiysddBXH","trusted":true},"cell_type":"code","source":"data = pd.read_csv('preprocessed_data.csv')\nhydro = data[data['ID'] == '05RE003']\nhydro['Water Level_previous'] = hydro[\"Value\"].shift(1) \nhydro['WL_pct'] = 100*(hydro[\"Value\"]  - hydro['Water Level_previous'] ) / hydro['Water Level_previous']\nhydro.dropna(inplace = True)","execution_count":4,"outputs":[]},{"metadata":{"id":"IH6ZkfoKJRoq"},"cell_type":"markdown","source":"## Statistical Features "},{"metadata":{"id":"kclt08RZJRoq","trusted":true},"cell_type":"code","source":"hydro['WL_mean_12'] = hydro['WL_pct'].rolling(12).mean()\nhydro['WL_mean_18'] = hydro['WL_pct'].rolling(18).mean()\nhydro['WL_mean_24'] = hydro['WL_pct'].rolling(24).mean()\n\nhydro['WL_std_12']  = hydro['WL_pct'].rolling(12).std()\nhydro['WL_std_24']  = hydro['WL_pct'].rolling(24).std()\n\nhydro['WL_lag_12']  = hydro['WL_pct'].shift(12)\nhydro['WL_lag_6']  = hydro['WL_pct'].shift(6)\n\nhydro.dropna(inplace = True )","execution_count":5,"outputs":[]},{"metadata":{"id":"ZlEH3q85JRor","trusted":true},"cell_type":"code","source":"num_feat = ['WL_pct','WL_mean_12','WL_mean_18','WL_mean_18','WL_mean_24','WL_std_12','WL_std_24','WL_lag_12','WL_lag_6']","execution_count":6,"outputs":[]},{"metadata":{"id":"9orGYXdnJRor"},"cell_type":"markdown","source":"## Time Based Features "},{"metadata":{"id":"un5Rh00WJRor","trusted":true},"cell_type":"code","source":"hydro['Date'] = pd.to_datetime(hydro['Date'])\nhydro['hour'] = hydro['Date'].dt.hour\nhydro['dayOfweek'] =  hydro['Date'].dt.dayofweek\nhydro['month'] =  hydro['Date'].dt.month","execution_count":7,"outputs":[]},{"metadata":{"id":"xOr60DA9JRor","trusted":true},"cell_type":"code","source":"cat_feat = ['hour','dayOfweek','month']","execution_count":8,"outputs":[]},{"metadata":{"id":"FEjnhrYLJRos","trusted":true},"cell_type":"code","source":"embbedded_size  = [(24,12),(7,4),(12,6)]","execution_count":9,"outputs":[]},{"metadata":{"id":"D1Y4V1MGJRos"},"cell_type":"markdown","source":"# Modling Part "},{"metadata":{"id":"kRe4qMI1JRos","trusted":true},"cell_type":"code","source":"seq_len = len(hydro)\ntrain_data = hydro.iloc[:int(0.8*seq_len)] \nval_data = hydro.iloc[int(0.8*seq_len):] ","execution_count":10,"outputs":[]},{"metadata":{"id":"90JjQTQmJRos"},"cell_type":"markdown","source":"## Stacked LSTM "},{"metadata":{"id":"ACGykTEtJRot","outputId":"4ceaf237-c42c-4815-d69f-968826fb0c6f","trusted":true},"cell_type":"code","source":"# Hyperparameters \ntrain_batch_size = 32\nvalid_batch_size = 16\nepochs = 100\ninput_size = len(num_feat)\nhidden_size = 32\nlr = 1e-4\ndevice = torch.device('cuda')\nwindow_size = 24  \npath = 'LSTM_Staked.pth'\nverbose = False\n\ntrain_dataset = hydro_dataset(train_data , window_size , num_feat , cat_feat )\nvalid_dataset = hydro_dataset(val_data , window_size , num_feat , cat_feat )\n\nstacked_lstm = StackedLSTMs(input_size,hidden_size)\nstacked_lstm = stacked_lstm.to(device)\nval_loss, train_loss = run(\n    stacked_lstm,\n    train_dataset,\n    valid_dataset,\n    lr,\n    epochs,\n    train_batch_size,\n    valid_batch_size,\n    device,\n    path,\n    verbose , \n    is_forcaster = True \n)","execution_count":11,"outputs":[{"output_type":"stream","text":"--------- Epoch 0 ---------\n train_loss  = 0.004113546538164783\n val_loss  = 0.00015200092688650733\n","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-523d5aebc190>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mverbose\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mis_forcaster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m )\n","\u001b[0;32m/kaggle/working/Water-Level-Forecasting/utils/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(model, train_dataset, valid_dataset, lr, EPOCHS, TRAIN_BATCH_SIZE, VALID_BATCH_SIZE, device, path, verbose, is_forcaster, is_added_auto_encoder)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_forcaster\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             tr_loss = train_fn_forcaster(\n\u001b[0;32m--> 210\u001b[0;31m                 \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_added_auto_encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m             )\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/working/Water-Level-Forecasting/utils/engine.py\u001b[0m in \u001b[0;36mtrain_fn_forcaster\u001b[0;34m(data_loader, model, optimizer, device, verbose, is_added_auto_encoder)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/optimization.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[0;31m# In-place operations to update the averages at the same time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eps\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"id":"spL5zXeB3zpf"},"cell_type":"markdown","source":"# Auto Encoder + LSTM Stacked "},{"metadata":{"id":"f7BVP3Bm7YI6","outputId":"4230cbd0-4909-4b42-8489-849e0bbfaa41","trusted":true},"cell_type":"code","source":"# Hyperparameters \ntrain_batch_size = 128\nvalid_batch_size = 64\nepochs = 200\ninput_size = len(num_feat)\nhidden_size = 32\nlr = 5e-4\ndevice = torch.device('cuda')\nwindow_size = 24  \npath = 'LSTM_Staked.pth'\nverbose = False\nemb_size = 8\n\ntrain_dataset = hydro_dataset(train_data , window_size , num_feat , cat_feat )\nvalid_dataset = hydro_dataset(val_data , window_size , num_feat , cat_feat )\n\nautoencoder_lstm = LSTMAutoEncoder(input_size = input_size ,hidden_size = hidden_size,emb_size= emb_size )\nautoencoder_lstm = autoencoder_lstm.to(device)\n\nval_loss, train_loss = run(\n    autoencoder_lstm,\n    train_dataset,\n    valid_dataset,\n    lr,\n    epochs,\n    train_batch_size,\n    valid_batch_size,\n    device,\n    path,\n    verbose , \n    is_forcaster = True , \n    is_added_auto_encoder = True,\n)","execution_count":null,"outputs":[]},{"metadata":{"id":"_HICvxACJkKq"},"cell_type":"markdown","source":"## Evaluation "},{"metadata":{"id":"2kPlMnaJuwER","trusted":true},"cell_type":"code","source":"def mean_absolute_percentage_error(y_true, y_pred): \n    y_true, y_pred = np.array(y_true), np.array(y_pred)\n    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100","execution_count":null,"outputs":[]},{"metadata":{"id":"68PV7Q0WJkB8","outputId":"abcf97c2-fbcd-46b7-f3f8-4192f451b3b0","trusted":true},"cell_type":"code","source":"val_data = val_data.iloc[window_size:]\n\npred = predict( stacked_lstm , valid_dataset)\nval_data['WL_pct_hat'] = pred / 100\nval_data['WL_hat_stacked_lstm'] = val_data['Water Level_previous'] * (1+val_data['WL_pct_hat'] )\n\npred = predict( autoencoder_lstm , valid_dataset ,is_added_auto_encoder = True )\nval_data['WL_pct_hat'] = pred / 100\nval_data['WL_hat_autoencoder_lstm'] = val_data['Water Level_previous'] * (1+val_data['WL_pct_hat'] )\n\nfig = make_subplots()\nfig.add_trace(go.Scatter( y=val_data['Value'].values, name='Ground Truth values'))\nfig.add_trace(go.Scatter( y=val_data['WL_hat_stacked_lstm'].values ,name='stacked_lstm predictions'))\nfig.add_trace(go.Scatter( y=val_data['WL_hat_autoencoder_lstm'].values ,name='LSTM + AutoEncoder  predictions'))\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"w_Dii7Nm_grT","outputId":"f334c9da-766f-4965-9928-a66354a79415","trusted":true},"cell_type":"code","source":"plt.plot( val_data['Value'].values, label='Ground Truth values')\nplt.plot( val_data['WL_hat_stacked_lstm'].values ,label='stacked_lstm predictions')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"q5P7iilHmt3B","outputId":"89b476b3-8f04-4f6a-e9b9-f4b16c605915","trusted":true},"cell_type":"code","source":"plt.plot( val_data['Value'].values, label='Ground Truth values')\nplt.plot( val_data['WL_hat_autoencoder_lstm'].values ,label=' LSTM + AutoEncoder predictions ')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"g2uoEbe3_-qi","outputId":"0a7e417f-b0cb-46d2-9e50-36c60402ce07","trusted":true},"cell_type":"code","source":"print('LSTM Stacked Model Results')\nprint('MSE = ' , mean_squared_error(val_data['Value'], val_data['WL_hat_stacked_lstm']))\nprint('RMSE = ', math.sqrt(mean_squared_error(val_data['Value'], val_data['WL_hat_stacked_lstm'])))\nprint('mean_absolute_error = ', mean_absolute_error(val_data['Value'], val_data['WL_hat_stacked_lstm']))\nprint('mean_absolute_percentage_error = ', mean_absolute_percentage_error(val_data['Value'], val_data['WL_hat_stacked_lstm']))","execution_count":null,"outputs":[]},{"metadata":{"id":"GJnSLMOQtCe7","outputId":"c9c41513-0738-4d95-a3f7-876e589ccef5","trusted":true},"cell_type":"code","source":"print('LSTM + AutoEncoder Model Results')\nprint('MSE = ' , mean_squared_error(val_data['Value'], val_data['WL_hat_autoencoder_lstm']))\nprint('RMSE = ', math.sqrt(mean_squared_error(val_data['Value'], val_data['WL_hat_autoencoder_lstm'])))\nprint('mean_absolute_error = ', mean_absolute_error(val_data['Value'], val_data['WL_hat_autoencoder_lstm']))\nprint('mean_absolute_percentage_error = ', mean_absolute_percentage_error(val_data['Value'], val_data['WL_hat_autoencoder_lstm']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}